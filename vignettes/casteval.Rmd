---
title: "Evaluate time series forecasts with casteval"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{casteval}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  strip.white=TRUE
)

library(casteval)
```
**TODO**

1. clean up code in examples (_e.g._, using `rep()`)

# Overview

`{casteval}` is an R package that helps you automate the evaluation of time series forecasts.
It provides functionality for formatting, processing, scoring, and visualizing forecasts.

A typical workflow using `{casteval}` is:

1. [**Create a forecast object**](#create-a-forecast-object) by inputting a forecast and its metadata into `create_forecast()`
2. [**Score the forecast**](#score-a-forecast) using a forecast object, corresponding observations against which to score, and a scoring function
3. [**Visualize the forecast**](#visualize-forecast-evaluation) using `plot_forecast()` with a scorred forecast and observations

This vignette guides you through this process. 
<!-- In this vignette, we demonstrate `{casteval}`'s main functionality via deliberately simple examples.
For a more realistic start-to-finish demonstration of the package's usage with real forecasts, please see [`vignette("denmark2020")`](denmark2020.html). -->

# Create a forecast object {#create-a-forecast-object}

In order to create a forecast object, a forecast must first be cast in one of the accepted formats, namely as a [data frame](#forecast-data-frame) or as a [list](#forecast-list).

## Forecasts input as data frames {#forecast-data-frame}

**Forecast data frames** must contain:

1. a `time` column, which can contain either numbers, dates, or date-times
1. forecast data, which can be passed as raw or summarized. 

**Raw forecast data** are the individual realizations of a model. **Summarized forecast data** describes an ensemble of realizations by quantiles computed for each time point.

### Raw forecast data

Raw forecast data must be passed in a column named `val`. A `sim` column may be provided optionally to identify different realizations (enables some scoring and plotting features).

```{r fdf_raw}
# raw forecast over with numeric times, without simulation numbers
data.frame(
  time=c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),
  val=c(100,101,102,110,111,112,120,121,122,130,131,132,140,141,142)
)

# raw forecast data with dates, with simulation numbers
data.frame(
  time=lubridate::as_date(c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5)),
  sim=c(1,2,3,1,2,3,1,2,3,1,2,3,1,2,3),
  val=c(100,101,102,110,111,112,120,121,122,130,131,132,140,141,142)
)
```

### Summarized forecast data

Summarized forecast data may be stored in the following columns:

- Quantile columns must start with `val_q` followed by a number from 0 to 100, _e.g._, `val_50` would be the 50th quantile, _i.e._, the median
- The mean column must be named `val_mean`

Note that summarized data never contains a `sim` column.

```{r fdf_summarized}
# summarized forecast data with the 25th, 50th, and 75th percentiles
data.frame(
  time=lubridate::as_datetime(1:5),
  val_q25=c(100,105,103,104,105),
  val_q50=c(201, 210, 205, 201, 200),
  val_q75=c(304, 305, 303, 303, 302)
)

# summarized forecast data with the mean, and the 2.5th and 97.5th percentiles
data.frame(
  time=1:5,
  val_q2.5=c(100,103,104,105,102),
  val_mean=c(150,155,160,155,154),
  val_97.5=c(200,200,2204,205,206)
)
```

All forecast data columns (`val`, `val_*`) as well as the `sim` column must be numeric.

## Forecasts input as lists {#forecast-list}

Forecast data frames are straightforward representations forecasts, though they are innefficient for raw forecast data as the `time` column gets repeated for each realization. If you have particularly long forecasts and/or many realizations, forecast data frames can quickly grow large, which can be slow to work with. Instead, you may wish to represent your forecast as a list.

`{casteval}` accepts raw forecast data as a named list with the following entries:

  - `time`: a single vector of times as numbers, dates, or date-times
  - `vals`: a list of numeric vectors containing the forecasted values, one per realization, where each vector is the same length as `time`

Since the individual realizations can be inferred from this casting, there is no need to provide additional information to identify individual realizations (as we did with the `sim` column [above](#forecast-data-frame)) in order to enable related downstream features.

## `create_forecast()` {#forecast-object}

**Forecast objects** are created with `create_forecast()`.
Its first argument is `dat`, which is the forecast data in one of the formats described [above](#create-a-forecast-object).

`create_forecast()` accepts forecast metadata as additional, optional arguments:

- `name`: a label for the forecast. Plotting functions will use `name` to title the plots they produce.
- `forecast_time`: the time at which the forecast period begins in `dat`^[Time series forecasts can typically be divided into a fit period and a forecast period, distinguished by whether or not observations were available at the time of forecast, respectively. It can be useful in visualizing and/or scoring forecasts to distinguish between these two periods.]. The `forecast_time` format must match that of the times in the `time` entry of `dat`, and can be used in scoring functions to compute scores only after times relative to `forecast_time`.

```{r create_forecast}
# forecast data with 4 time points and an ensemble of 3 simulations
dat1 <- list(
  time=1:4,
  vals=list(
    c(100, 102, 110, 108),
    c(200, 195, 197, 196),
    c(300, 301, 300, 302)
  )
)

fc1 <- create_forecast(dat1, name="forecast 1", forecast_time=3)

# the same data but formatted as a forecast data frame
dat2 <- data.frame(
  time=rep(1:4, each=3),
  sim=rep(1:3, times=4),
  val=c(100, 200, 300, 102, 195, 301, 110, 197, 300, 108, 196, 302)
)

fc2 <- create_forecast(dat2, name="forecast 2", forecast_time=3)

print(fc1)

# aside from the order of rows, the resulting forecast data frames are identical
waldo::compare(dplyr::arrange(fc1$data, time), fc2$data)

# mean-and-quantiles forecast data
dat3 <- data.frame(
  time=1:5,
  val_q2.5=c(100,103,104,105,102),
  val_mean=c(150,155,160,155,154),
  val_q97.5=c(200,200,2204,205,206)
)

# note how we omit `forecast_time`
fc3 <- create_forecast(
  dat3,
  name="forecast 3"
)

print(fc3)
```

`create_forecast()` returns a forecast object, which is a list with the following fields:

- `data`: a [forecast data frame](#forecast-data-frame)
- `name`: the name of the forecast, if provided
- `forecast_time`: when the forecast was made, if provided 

```{r forecast_object}
# a forecast object with no optional metadata
list(
  data=data.frame(
    time=1:5,
    val=6:10
  ),
  name=NULL,
  forecast_time=NULL
)

# a forecast object with metadata
list(
  data=data.frame(
    time=lubridate::as_date(1:5),
    val=6:10
  ),
  name="A forecast",
  forecast_time=lubridate::as_date(3)
)
```

This list could be created by hand, without the help of `create_forecast()`, but we recommend the latter approach as `create_forecast()` validates its inputs to avoid issues downstream.
For example, it checks that:

- `forecast_time`'s type is consistent with `dat`
- quantile values are logically possible (_e.g._, median values can't be smaller than the 25th quantiles)
- there are no conflicting rows (_e.g._, there can't be two rows with the same time reporting different means)

# Score a forecast {#score-a-forecast}

Forecasts are scored against observations, which must be passed to `{casteval}` in a specific format.

## Observations data frame {#observations-data-frame}

Observations are passed to `{casteval}` in a data frame with a `time` column and a `val_obs` column.
Similar to [forecast data frames]{#forecast-data-frame}, `time` may be either numeric, dates, or date-times.
`val_obs` must be numeric.

```{r obsdf}
# An observations data frame
data.frame(
  time=1:5,
  val_obs=c(50,60,55,57,59)
)
```

## Scoring functions

`{casteval}` includes several scoring funcions, such as `accuracy()`, `log_score()`, and `bias()`, which are explained in more detailed in the following sections. In general, scoring functions accept the following arguments:

- `fcst`: a [forecast object](#forecast-object)
- `obs`: an [observations data frame](#observations-data-frame)
- Additional arguments specific to particular scoring functions, such as [the `summarise` flag](#summarise-flag)

In order for scoring to be possible, `fcst` and `obs` must use the same `time` type. If `fcst` or `obs` contain times not contained by the other, these times will be ignored when scoring.

If the forecast object includes a forecast date, then all data prior to `fcst$forecast_time` will be ignored when scoring.

### The `summarize` flag {#summarise-flag}

Many scoring functions calculate intermediate scores for each time point, and then select/combine those scores in order to return a single value.
These functions accept an optional `summarize` parameter, which is a boolean.

If `summarize=TRUE` (the default), the scoring function will usually return the score as a single number^[One exception is `accuracy()`, which returns a vector of numbers if a list of quantile pairs is provided, as expained [below](#accuracy-score)]. 

If `summarise=FALSE`, the scoring function will return a data frame with `time`, `obs`, and `score` columns, containing the observations and scores calculated for each time point that was scored.
The type of the `score` column is not necessarily numeric (for example, in `accuracy()`, it is logical in this case instead).

## Accuracy score {#accuracy-score}

`accuracy(fcst, obs, quant_pairs=NULL, summarize=TRUE)` calculates the proportion of observations that fall inside a quantile interval of the forecast data.

If `fcts` contains summarized forecast data, accuracy will be calculated using the quantiles provided. 
If `fcst` contains raw forecast data, you can use the `quant_pairs` argument to specify a pair of quantiles (_e.g._, `c(2.5, 97.5)`) or a list of pairs of quantiles (_e.g._, `list(c(2.5, 97.5), c(10, 90))`) against which to calculate accuracy. 
If a list of pairs of quantiles is provided, a separate score will be calculated for each pair.

If `summarize` is `TRUE`, then the score(s) will be returned as a vector of numbers from 0 to 1, one score per quantile pair. 
If `summarize` is `FALSE`, an accuracy score will be provided for each observation (as a boolean). 
If more than one pair of quantiles is requested, then the returned data frame will contain an additional column named `pair`, which will indicate which quantile pair each score corresponds to.

### Examples

```{r accuracy_examples}
# A forecast with raw data
fc1 <- create_forecast(data.frame(
  time=rep(1:5, each=11),
  val=rep(0:10, 5)
))

# A forecast with quantile data
fc2 <- create_forecast(dplyr::tibble(
  time=1:5,
  val_q5=c(0.5,0.5,0.5,0.5,0.5),
  val_q10=c(1,1,1,1,1),
  val_q25=c(2.5,2.5,2.5,2.5,2.5),
  val_q75=c(7.5,7.5,7.5,7.5,7.5),
  val_q90=c(9,9,9,9,9),
  val_q95=c(9.5,9.5,9.5,9.5,9.5)
))

# Another forecast with quantile data
fc3 <- create_forecast(data.frame(
    time=1:5,
    val_q2.5=c(6,6,6,6,6),
    val_q97.5=c(10,10,10,10,10)
))

obs <- data.frame(time=1:5, val_obs=c(0, 2.4, 5, 9.5, 10))

# Calculate accuracy from raw data
accuracy(fc1, obs, quant_pairs=c(25, 75))

# Calculate the accuracy for every quantile pair present
accuracy(fc2, obs)

# Calculate the accuracy for a subset of quantile pairs
accuracy(fc2, obs, quant_pairs=list(c(5,95), c(25,75)))

# Calculate accuracy for only one quantile pair
accuracy(fc2, obs, quant_pairs=c(5, 95))

# If `forecast_time` is NULL, every time point in the forecast will be scored
accuracy(fc3, obs)

# Otherwise, everything prior to `forecast_time` will be ignored
fc3$forecast_time <- 3
accuracy(fc3, obs)

# We can see what is happening behind the scenes by passing `summarize=FALSE`
df <- accuracy(fc3, obs, summarize=FALSE)
df
mean(df$score)

# `pair` column maps rows to quantile pairs
accuracy(fc2, obs, summarize=FALSE)
```

## Logarithmic score

`log_score(fcst, obs, at=NULL, after=NULL, summarize=TRUE, bw=NULL)` calculates the (positive) log score of a forecast.
It uses [Kernel Density Estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation) (KDE) to obtain a probability distribution of forecasted values at each point in time in the forecast.
If `f(x)` is the estimated probability distribution and `x_0` is the corresponding observation, then the log score at that point in time is `log(f(x_0))` (`log()` is the natural logarithm).

`fcst` must contain raw forecast data with 2 or more values per time point.

If `summarize` is `TRUE`, one score will be returned and it will be based on either the score at time `at` or at `fcst$forecast_time + after`, depending on whether `at` or `after` is provided. (Only one is accepted at a time.)

If `summarize` is `FALSE`, then `at` and `after` are ignored, and the output will be a data frame as described above, with scores for each observation.

The KDE requires a bandwidth in order to calculate the forecast distribution at each observation time.
If `bw` is left `NULL`, then a reasonable bandwidth will be automatically determined.
Otherwise, the value of `bw` (which must be a number greater than 0) will be used. See `?log_score` for more details.

### Visualizing the KDE

When evaluating forecasts using `log_score()` you may want to inspect inspect the KDE as a confidence check, especially if the forecast data is very sparse.
You may also want to see how setting the `bw` parameter affects the resulting distribution, or whether the automatically calculated bandwidth is acceptable. 

`plot_KDE()` allows you to do this. Like `log_score()`, it accepts the parameters `fcst`, `obs` (which is now optional), `at`, `after`, and `bw`.
It also accepts the optional parameters `from`, `to`, `n`, and `binwidth` (not to be confused with bandwidth). See `?plot_KDE` for a detailed explanation of these extra parameters.

`plot_KDE()` will plot the following elements:

- the data points of the `fcst` and/or `obs` at the time point specified by `at` or `after`
- a histogram showing the distribution of `fcst`'s data points (once again specified by `at` or `after`), normalized to integrate to 1 in order to be comparable to a probability density
- the density curve calculated by the KDE

### Examples

```{r log_score_examples}
# generated using `rnorm(20) + 10`
d <- c(10.609344, 10.383797, 11.102006, 10.232616, 11.372632, 11.489963, 10.359282, 10.303749,
  7.477219,  9.612921,  8.568241, 11.467244,  9.979756, 10.226105, 9.592584,  9.582751,  8.674618,
  8.706757,  9.810594, 10.752879)

fcst <- create_forecast(
  data.frame(time=rep(1:5, each=20), val=rep(d,5)),
  forecast_time=2
)

obs <- data.frame(time=1:5, val_obs=c(2, 7, 10, 11, 100))

# get the score at time 3
log_score(fcst, obs, at=3)

# get the score at time `fcst$forecast_time + 2` (4)
log_score(fcst, obs, after=2)

# get all the scores as part of a data frame
log_score(fcst, obs, summarize=FALSE)

# check the KDE at time 4 with default binwidth
# the observation point shows up as a vertical line
plot_KDE(fcst, obs, at=4)

# check the KDE at time 4 with a too-low binwidth (making the resulting distribution very jagged)
plot_KDE(fcst, obs, at=4, bw=0.2)

# check the KDE at time 4 with a too-high binwidth (resulting in an underconfident distribution)
plot_KDE(fcst, obs, at=4, bw=2)
```

## Bias

`bias(fcst, obs, summarize=TRUE)` calculates how much a forecast overpredicts and underpredicts each observed value, and returns the result as a number between -1 and 1, where -1 means all observations were  underpredicted and 1 means all observations were overpredicted.

It searches for these three kinds of forecast data:

1. raw data (`val`)
2. mean data (`val_mean`)
3. median data (`val_q50`)

It uses the first kind that it can find to calculate the bias.

## Defining your own scoring functions

You are free to define your own scoring functions and use them just like `{casteval}`'s scoring functions.
Like the functions described above, it should accept a forecast object `fcst`, an observations data frame `obs`, and possibly additional arguments.
If your scoring function returns a score for each observation (in [the same way that `summarize=FALSE` does](#summarise-flag) for the functions above), then the plotting functions can readily use this added information when visualizing forecast scores (discussed further below).

# Visualize forecast evaluation {#visualize-forecast-evaluation}

`{casteval}` provides plotting functions which allow you to visualize your forecasts, observations, and sometimes scores.
Several modular functions (`plot_ensemble()`, `plot_observations()`, `plot_quantile_intervals()`) implement individual plotting functionality, while the more user-friendly `plot_forecast()` combines them all.
We describe these functions below.

## Plot a forecast

`plot_forecast(fcst, obs=NULL, quant_pairs=NULL, score=NULL)` plots a forecast. It also optionally overlays observations, quantile intervals, and color-codes the observations based on score.

`quant_pairs` is like the parameter with the same name in `accuracy()`.
The only difference is that an error will not be raised if `quant_pairs` is `NULL` and quantile pairs can't be inferred, or if `quant_pairs` is an empty list (in which case quantile intervals simply won't be plotted).

`score` should be a scoring function which supports the `summarize` flag.
`plot_forecast()` will run `score(fcst, obs, summarize=FALSE)`, and use the resulting data frame's `score` column to color code the observation points.

Some wrapping of the builtin scoring functions may be required before passing them to `plot_forecast()`.
For example, `accuracy()` will require a single quantile pair to be passed to it as well.

```{r plot_forecast_examples}
# Create a forecast
fc <- create_forecast(list(
  time=1:10,
  vals=list(
    c(1,2,3,5,4,5,4,6,6,5),
    c(1,3,5,4,6,5,7,9,8,8),
    c(1,4,3,4,5,6,5,3,2,2),
    c(1,2,4,5,7,8,7,9,10,9)
  )
))

# Plot it
plot_forecast(fc)

# Plot it and display 3 quantile intervals
plot_forecast(fc, quant_pairs=list(c(25,75), c(2.5,97.5), c(5,95)))

# Create some observations
obs <- data.frame(time=1:10, val_obs=c(1,4,8,10,11,8,5,3,3,2))

# Plot them over the forecast and its confidence intervals
plot_forecast(fc, obs=obs, quant_pairs=list(c(25,75), c(2.5,97.5), c(5,95)))

# We use a function factory to wrap accuracy() (see `?make_accuracy`)
acc <- make_accuracy(c(5,95))
# Identify the observations inside the 5%-95% quantile interval
plot_forecast(fc, obs=obs, quant_pairs=list(c(25,75), c(2.5,97.5), c(5,95)), score=acc)

# Do the same thing with `log_score()`
# `graph_forecast()` automatically passes `summarize=FALSE` to
# scoring functions in order to obtain the score for each day
plot_forecast(fc, obs=obs, score=log_score)
```
