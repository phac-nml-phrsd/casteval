---
title: "Automate forecast evaluation using `{casteval}`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Automate forecast evaluation using `{casteval}`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  strip.white=TRUE
)

library(casteval)
```


# Overview

`{casteval}` is an R package that helps you automate the evaluation of time series forecasts.
It provides functionality for formatting, processing, scoring, and visualizing forecasts.

A typical workflow using `{casteval}` might go as follows:

1. We pass forecast data to `create_forecast()`, which returns a forecast object in a standardized format
2. We pass the forecast object and corresponding observations into scoring functions such as `bias()`, `log_score()`, `accuracy()`, which evaluate the forecast
3. We pass the forecast object and corresponding observations into plotting functions such as `plot_forecast()`, which lets us visualize the forecast. Scoring functions can also work together with plotting functions in order to help visualize forecast scores

In this vignette, we demonstrate `{casteval}`'s main functionality via deliberately simple examples. For a more realistic start-to-finish demonstration of the package's usage with real forecasts, please see [`vignette("denmark2020")`](denmark2020.html).

# Data format

`{casteval}` expects the data you pass it to be in certain formats.
In particular:

- *Forecast data frames* contain forecast data
- *Forecast objects* contain metadata about a forecast, as well as a forecast data frame
- *Observations data frames* contain observations data

`{casteval}` contains tools which aid in the creation and manipulation of these objects, to make your life easier.
These tools are described in later sections.

## Forecast data frames

All forecast data frames contain a `time` column, which can contain either numbers, dates, or datetimes.
In addition, they should contain either unsummarized or summarized forecast data, but not both.

Unsummarized data is stored in a `val` column.
A `sim` column may optionally be provided to specify simulation numbers in an ensemble of data.

```{r fdf_unsummarized}
# unsummarized forecast over with numeric times, without simulation numbers
data.frame(
  time=c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),
  val=c(100,101,102,110,111,112,120,121,122,130,131,132,140,141,142)
)

# unsummarized forecast data with dates, with simulation numbers
data.frame(
  time=lubridate::as_date(c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5)),
  sim=c(1,2,3,1,2,3,1,2,3,1,2,3,1,2,3),
  val=c(100,101,102,110,111,112,120,121,122,130,131,132,140,141,142)
)
```

Summarized data may be stored in the following columns:
- Quantile columns must start with `val_q` followed by a number from 0 to 100, e.x. `val_50` would be the median
- The mean column must be named `val_mean`

Note that summarized data never contains a `sim` column.

```{r fdf_summarized}
# summarized forecast data with the 25th, 50th, and 75th percentiles
data.frame(
  time=lubridate::as_datetime(1:5),
  val_q25=c(100,105,103,104,105),
  val_q50=c(201, 210, 205, 201, 200),
  val_q75=c(304, 305, 303, 303, 302)
)

# summarized forecast data with the mean, and the 2.5th and 97.5th percentiles
data.frame(
  time=1:5,
  val_q2.5=c(100,103,104,105,102),
  val_mean=c(150,155,160,155,154),
  val_97.5=c(200,200,2204,205,206),
)
```

All data columns as well as the `sim` column must be numeric.

## Forecast objects

A forecast object is a list with the following fields:

- `data`: a forecast data frame (see above)
- `name`: (optional) the name of the forecast
- `forecast_time`: (optional) the time that the forecast was created. Its type must match that of the times in `data`

Scoring functions will take `forecast_time` into account when scoring if it is provided.
Plotting functions will use `name` to title the plots they produce.

`{casteval}` provides a function for creating forecast objects, `create_forecast()`, which we describe below.
We recommend against creating or modifying forecast objects by hand, but it is useful to know what they look like.

```{r forecast_object}
# a forecast object with no optional metadata
list(
  data=data.frame(
    time=1:5,
    val=6:10
  ),
  name=NULL,
  forecast_time=NULL
)

# a forecast object with metadata
list(
  data=data.frame(
    time=lubridate::as_date(1:5),
    val=6:10
  ),
  name="A forecast",
  forecast_time=lubridate::as_date(3)
)
```

## Observations data frames

All observations data frames contain a `time` column and a `val_obs` column.
Similar to forecast data frames, `time` may be either numeric, dates, or date-times.
`val_obs` must be numeric.

An observations data frame may also contain a `score` column, which usually gets attached by a scoring function.
`score` can have many different types, but it is typically numeric or logical.

```{r obsdf}
# An observations data frame
data.frame(
  time=1:5,
  val_obs=c(50,60,55,57,59)
)

# An observations data frame that holds the score for some forecast
data.frame(
  time=lubridate::as_date(1:5),
  val_obs=c(50,60,55,57,59),
  score=c(1.5, 6, 0, -1, 5, 6)
)
```

# Creating forecast objects

You can create forecast objects using `create_forecast()`.
Its first argument is `dat`, which may be one of the following formats:

- A forecast data frame, as described above
- A list with fields `time` and `vals`, where:
  - `time` is a vector of either numbers, dates, or date-times
  - `vals` is a list of numeric vectors, where each vector is the same length as `time`. Each vector corresponds to a realization in the forecast

In addition, `create_forecast()` accepts the optional arguments `name` and `forecast_time`, which will be stored in the forecast object.

`create_forecast()` performs input validation on the provided parameters.
For example, it checks that:
- `forecast_time`'s type is consistent with `dat`
- quantile values are logically possible (e.x. the median can't be less than the 25th percentile)
- there are no conflicting rows (e.x. there can't be two rows with the same time providing the mean)

```{r create_forecast}
# forecast data with 4 time points and an ensemble of 3 simulations
dat1 <- list(
  time=1:4,
  vals=list(
    c(100, 102, 110, 108),
    c(200, 195, 197, 196),
    c(300, 301, 300, 302)
  )
)

fc1 <- create_forecast(dat1, name="forecast 1", forecast_time=3)

# the same data but formatted as a forecast data frame
dat2 <- data.frame(
  time=rep(1:4, each=3),
  sim=rep(1:4, time=3),
  val=c(100, 200, 300, 102, 195, 301, 110, 197, 300, 108, 196, 302)
)

fc2 <- create_forecast(dat2, name="forecast 2", forecast_time=3)

print(fc1)
waldo::compare(fc1$data, fc2$data)

# mean-and-quantiles forecast data
dat3 <- data.frame(
  time=1:5,
  val_q2.5=c(100,103,104,105,102),
  val_mean=c(150,155,160,155,154),
  val_97.5=c(200,200,2204,205,206),
)

# note how we omit `forecast_time`
fc3 <- create_forecast(
  dat3,
  name="forecast 3"
)

print(fc3)
```

# Scoring

Scoring functions accept the following arguments:

- A forecast object `fcst`
- An observations data frame `obs`
- Additional arguments specific to particular scoring functions

In order for scoring to be possible, `fcst` and `obs` must use the same time type.
That is to say, `fcst$data$time` and `obs$time` must have the same type.

If `fcst$forecast_time` is not `NULL`, then all data prior to `fcst$forecast_time` will be ignored when scoring `fcst`.

If `fcst` or `obs` contain times not contained by the other, they will be ignored when scoring.

### The `summarize` flag
Many scoring functions calculate intermediate values for each time point, and then select/combine those scores in order to return a single value.
These functions accept an optional `summarize` parameter, which is a boolean.

If `summarize` is set to `TRUE` (the default), the scoring function will return the score as a single number.

Otherwise, it will return a data frame with `time`, `obs`, and `score` columns, containing the observations and scores calculated for each time point that was scored.
The type of the `score` column is not necessarily numeric (for example, in `accuracy()`, it contains booleans).
One use of these unsummarized values is for color-coding observation points when graphing them.

The currently supported scoring functions are described below.

## Accuracy

`accuracy(fcst, obs, quant_pairs=NULL, summarize=TRUE)` calculates the rate at which the observations fall inside a quantile interval of the forecast's predicted values.

`quant_pairs` should be one of:
- `NULL`
- a pair of quantiles (e.x. `c(2.5, 97.5)`)
- a list of pairs of quantiles (e.x. `list(c(2.5, 97.5), c(10, 90))`)

If `quant_pairs` is not `NULL`, then a separate score will be calculated for each given pair of quantiles.
If `quant_pairs` is `NULL`, then `fcst` should contain quantile data, and the quantile pairs for scoring will be inferred from `fcst`'s quantile columns.

If `summarize` is `TRUE`, then the score(s) will be returned as a vector of numbers from 0 to 1.

If `summarize` is `FALSE`, then the returned data frame will contain an additional column named `pair`, which will indicate which quantile pair each row corresponds to.

### Examples

```{r accuracy_examples}
# A forecast with unsummarized data
fc1 <- create_forecast(data.frame(
  time=rep(1:5, each=10),
  val=rep(0:10, 5)
))

# A forecast with quantile data
fc2 <- create_forecast(dplyr::tibble(
  time=1:5,
  val_q5=c(0.5,0.5,0.5,0.5,0.5),
  val_q10=c(1,1,1,1,1,),
  val_q25=c(2.5,2.5,2.5,2.5,2.5),
  val_q75=c(7.5,7.5,7.5,7.5,7.5),
  val_q90=c(9,9,9,9,9),
  val_q95=c(9.5,9.5,9.5,9.5,9.5)
))

# Another forecast with quantile data
fc3 <- create_forecast(data.frame(
    time=1:5,
    val_q2.5=c(6,6,6,6,6),
    val_q97.5=c(10,10,10,10,10)
))

obs <- data.frame(time=1:5, val_obs=c(0, 2.4, 5, 9.5, 10))

# Calculate accuracy from unsummarized data
accuracy(fc1, obs, quant_pairs=c(25, 75))

# Calculate the accuracy for every quantile pair present
accuracy(fc2, obs)

# Calculate the accuracy for a subset of quantile pairs
accuracy(fc2, obs, quant_pairs=list(c(5,95), c(25,75)))

# Calculate accuracy for only one quantile pair
accuracy(fc2, obs, quant_pairs=c(5, 95))

# If `forecast_time` is NULL, every time point in the forecast will be scored
accuracy(fc3, obs)

# Otherwise, everything prior to `forecast_time` will be ignored
fc3$forecast_time <- 3
accuracy(fc3, obs)

# We can see what is happening behind the scenes by passing `summarize=FALSE`
df <- accuracy(fc3, obs, summarize=FALSE)
df
mean(df$score)

# `pair` column maps rows to quantile pairs
accuracy(fc2, obs, summarize=FALSE)
```

## Logarithmic score
`neglog(fcst, obs, at=NULL, after=NULL, summarize=TRUE)` calculates the negative log score of a forecast.
`fcst` must contain raw data with 2 or more realizations per row.
It uses Kernel Density Estimation (KDE) to obtain a probability distribution for each point in time in the forecast.
If `f(x)` is the calculated probability distribution and `x0` is the corresponding observation, then the negative log score at that point in time is `-log(f(x0))`, where `log` is the natural logarithm.

`at` and `after` can be used to specify which point in time to return the score of.
If both are left `NULL`, then all the calculated scores will be returned as part of a data frame.
`at` specifies a particular time, while `after` specifies a time relative to `fcst$forecast_time`.

### Examples

```{r neglog_examples}

# `rnorm(20) + 10`
d <- c(10.609344, 10.383797, 11.102006, 10.232616, 11.372632, 11.489963, 10.359282, 10.303749,
  7.477219,  9.612921,  8.568241, 11.467244,  9.979756, 10.226105, 9.592584,  9.582751,  8.674618,
  8.706757,  9.810594, 10.752879)

fcst <- create_forecast(
  dplyr::tibble(time=1:5, raw=list(c(d, d, d, d, d))),
  forecast_time=2
)

obs <- data.frame(time=1:5, obs=c(2, 7, 10, 11, 100))

# get the score at time=3
neglog(fcst, obs, at=3)

# get the score at `fcst$forecast_time + 2` (4)
neglog(fcst, obs, after=2)

# get all the scores as part of a data frame
neglog(fcst, obs, summarize=FALSE)

# `at` and `after` are mutually exclusive
try(neglog(fcst, obs, at=3, after=1))
```

## Bias
`bias(fcst, obs, summarize=TRUE)` calculates how much a forecast overpredicts and underpredicts each observed value, and returns the result as a number between -1 and 1, where -1 means 100% underprediction and 1 means 100% overprediction.

*Note: while `bias()` has a `summarize` parameter, its output is currently not fully compatible with `graph_forecast()`*

It searches for these three kinds of data:

1. raw realizations (`raw`)
2. mean data (`mean`)
3. median data (`quant_50`)

It uses the first kind that it can find to calculate the bias.

## Defining your own scoring functions
Let's say you want to define your own scoring function. It should accept the following arguments:
- `fcst`: a forecast object, such as the ones returned by `create_forecast()`
- `obs`: an observations data frame

It can also optionally support the argument `summarize=TRUE`, in which case it should handle the flag like the builtin scoring functions do (see above).

By default, your function should return a single number indicating the score.

# Visualization

*Note: `{casteval}` implements several more modular graphing functions which are not currently exported, such as `graph_observations()`, `graph_quantiles()`, etc. If it would be useful to have these available then this may change*

`graph_forecast(fcst, obs=NULL, confs=NULL, score=NULL)` graphs a forecast. It also optionally overlays observations, confidence intervals, and color-codes the observations based on score.

```{r graph_forecast_examples}
# Create a forecast
fc <- create_forecast(list(
  time=1:10,
  ensemble=list(
    c(1,2,3,5,4,5,4,6,6,5),
    c(1,3,5,4,6,5,7,9,8,8),
    c(1,4,3,4,5,6,5,3,2,2),
    c(1,2,4,5,7,8,7,9,10,9)
  )
))

# Graph it
graph_forecast(fc)

# Graph it and display the 50%, 90%, and 95% confidence intervals
graph_forecast(fc, confs=c(50,95,90))

# Create some observations
obs <- data.frame(time=1:10, obs=c(1,4,8,10,11,8,5,3,3,2))

# Graph them over the forecast and its confidence intervals
graph_forecast(fc, obs=obs, confs=c(50,90,95))

# Wrap `accuracy()` to get the 90% confidence interval
acc90 <- \(...) accuracy(..., interval=c(5,95))
# Use `acc90()` to identify the observations outside the condfidence interval
graph_forecast(fc, obs=obs, confs=c(50,90,95), score=acc90)

# Do the same thing with `neglog()`
# `graph_forecast()` automatically passes `summarize=FALSE` to
# scoring functions in order to obtain the score for each day
graph_forecast(fc, obs=obs, score=neglog)
```