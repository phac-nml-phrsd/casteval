---
title: "Automate forecast evaluation using `{casteval}`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Automate forecast evaluation using `{casteval}`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(casteval)
```


# Overview
`{casteval}` is an R package that helps you automate the evaluation of time series forecasts.
It provides functionality for formatting, processing, scoring, and visualizing forecasts.

# Input formatting
*NB: As this is a work in progress, the number of formats supported is still limited*

`{casteval}` can take various forecast formats as input. Each forecast must at minimum be a data frame with a `time` column and one or more data columns.

## Time column

The current supported `time` column types are:

- `numeric` (-1, 0, 1, 1.5, etc.),
- `Date` (_e.g._ from `{lubridate}`),
- date-time formats `POSIXct` and `POSIXt`.

## Data columns

All data columns must contain `numeric` data.

The current supported data columns are:

- `raw`: values for individual realisations of a forecast
- `mean`: mean value for each time point of an ensemble
- `quant_x`: quantile for each time point of an ensemble, where `x` is a percentage from 0 to 100 (_e.g._, `quant_50` would represent the 50th quantile, or median)

## Examples

The following are examples of valid forecast input formats to `{casteval}`:

```{r input_formats}
# Create some dates and date-times for convenience
dates <- c(lubridate::ymd("2024-01-01"), lubridate::ymd("2024-01-02"), lubridate::ymd("2024-01-03"))
datetimes <- c(lubridate::ymd_hms("2024-02-01_12:00:00"), lubridate::ymd_hms("2024-02-01_13:00:00"), lubridate::ymd_hms("2024-02-01_14:00:00"))

# A forecast with date-times and raw data points
df1 <- data.frame(
  time=datetimes, 
  raw=c(400, 450, 500)
)
head(df1)

# A forecast with dates and quartiles
df2 <- data.frame(
  time=dates, 
  quant_25=c(50, 60, 70), 
  quant_50=c(100, 110, 120), 
  quant_75=c(150, 160, 170)
)
head(df2)

# A forecast with numeric times, the mean, and 95% confidence interval
df3 <- data.frame(
  time=c(1, 2, 3), 
  mean=c(1000, 900, 800), 
  quant_2.5=c(950, 850, 750), 
  quant_97.5=c(1050, 950, 850)
)
head(df3)

# A forecast with raw data over multiple realizations of the model/simulation
# We use tibbles here to make entering the list-column easier
time_vec <- c(1, 2, 3)
realized_t1 <- c(100, 200, 300)
realized_t2 <- c(102, 195, 301)
realized_t3 <- c(110, 197, 300)
df4 <- dplyr::tibble(
  time=time_vec, 
  raw=list(realized_t1, realized_t2, realized_t3)
)
```

As demonstrated above, raw data can contain multiple realizations in a single day by storing a list of projected values in each row instead of a single value.
For instance, the `j`th value of the vector stored in row `i` of the input data frame would give the value of the `j`th realisation for time `i`. In this format, `{casteval}` expects that all vectors in such a list-column are the same length (every time point contains data for the same number of realisations).

# Passing forecasts to `{casteval}`

We start by passing our forecast to the `create_forecast()` function.
This function performs input validation and infers the format of the given forecast (_e.g._, raw realisations, ensemble summarised by mean and quantiles, etc.)
It then returns a named list containing metadata about the forecast as well as the given forecast data to pass to other package functions.
In addition to the data frame itself, `create_forecast()` accepts optional arguments, as illustrated in the examples below.

```{r create_forecast}
# A forecast with a name
fc1 <- create_forecast(df1, name="forecast 1")

# `name` and `forecast_time` are optional, and default to NULL
fc2 <- create_forecast(df2)

# A forecast with a name and a forecast time
# All data from before the given time will be ignored when scoring the forecast
# The given forecast time must have the same type as the values in the `time` column
fc3 <- create_forecast(df3, name="forecast 3", forecast_time=2)

# Metadata and data are easily accessible
print(fc3$name)
print(fc3$forecast_time)
print(fc3$time_type)
print(fc3$data_types)
print(fc3$data)
```

## Auto-aggregation

Raw realizations can be passed to `create_forecast()` in two ways:
- As one data frame
- As a list of data frames, one per realization

`create_forecast()` will automatically combine the list of data frames into one, provided that they have the same time types and all contain raw data.
For example, the two calls to `create_forecast()` below will have the same output.

```{r create_forecast_aggregation}
# Passing a single data frame with realizations already aggregated
fc4 <- create_forecast(df4)

a <- dplyr::tibble(time=time_vec, raw=c(realized_t1[1], realized_t2[1], realized_t3[1]))
b <- dplyr::tibble(time=time_vec, raw=c(realized_t1[2], realized_t2[2], realized_t3[2]))
c <- dplyr::tibble(time=time_vec, raw=c(realized_t1[3], realized_t2[3], realized_t3[3]))

# Passing a list of data frames to be automatically aggregated
fc5 <- create_forecast(list(a,b,c))

waldo::compare(fc4, fc5)
```

# Observations

Observations are formatted like single-realization raw data forecasts.
That is, they are a data frame with a `time` column and a `raw` column containing observations.

Note how observations are simply data frames, whereas forecasts are encapsulated by a named list.
My reasoning for this was that forecasts contain certain metadata (such as `forecast_time`) which affect the way they are evaluated.
This may change in future versions if it turns out that observations require metadata too, or if there is a better way to store metadata.

# Scoring

Scoring functions accept the following arguments:

- A forecast object `fcst` (such as the ones outputted by `create_forecast()`)
- A data frame of observations `obs` (as described above)
- Additional arguments specific to particular scoring functions

`fcst` and `obs` must use the same time type for scoring to be possible.
That is to say, `fcst$data$time` and `obs$time` must contain elements of the same type.

If `fcst$forecast_time` is not `NULL`, then all data prior to `fcst$forecast_time` will be ignored when scoring `fcst`.

If `obs` contains data for time points that `fcst` does not have, those time points will be ignored.
However, the reverse cannot happen (if `fcst` contains time points that `obs` does not have, an error will be raised).
In the future a flag might be added to tell the scoring functions to discard rows with missing observations.

Scoring functions typically return a single number indicating the score.

The currently supported scoring functions are described below.
Most of the examples are deliberately contrived in order to better illustrate the scoring functionality.

## `accuracy()`

`accuracy(fcst, obs, interval=NULL)` returns the rate at which the observations fall inside a confidence interval predicted by the forecast.
It returns a number from 0 to 1.

If the forecast contains raw data, `interval` must be a vector of two percentages.
The quantiles for these percentages will be calculated from the raw data and used to calculate the score.

If the forecast contains quantile data and `interval` is left as `NULL`, then `accuracy()` will try to use the lowest and highest provided quantiles to calculate the score.
If `interval` is provided, then `accuracy()` will use the corresponding quantiles in `fcst` to calculate the score.

### Examples

```{r accuracy_examples}
# forecast with raw data.
fc1 <- create_forecast(dplyr::tibble(
  time=1:5,
  raw=list(0:10, 0:10, 0:10, 0:10, 0:10)
))

# forecast with quantile data.
fc2 <- create_forecast(dplyr::tibble(
  time=1:5,
  quant_5=c(1,1,1,1,1),
  quant_25=c(2.5,2.5,2.5,2.5,2.5),
  quant_75=c(7.5,7.5,7.5,7.5,7.5),
  quant_95=c(9.5,9.5,9.5,9.5,9.5)
))

# a forecast with less symmetrical quantile data.
fc3 <- create_forecast(dplyr::tibble(
  time=1:5,
  quant_25=c(2.5,2.5,2.5,2.5,2.5),
  quant_50=c(5,5,5,5,5),
  quant_95=c(9.5,9.5,9.5,9.5,9.5)
))

obs <- data.frame(time=1:5, raw=c(0, 2.4, 5, 9.5, 10))

# calculate accuracy using the 50% confidence interval.
print(accuracy(fc1, obs, interval=c(25, 75)))
# calculate accuracy using highest and lowest quantiles (5% and 95% in this case).
print(accuracy(fc2, obs))
# calculate accuracy using provided quantiles.
print(accuracy(fc2, obs, interval=c(25, 95)))
# accuracy() refuses to automatically use the highest and lowest quantiles
# if they are not symmetrical.
try(
  print(accuracy(fc3, obs))
)
# specifying an interval fixes this
print(accuracy(fc3, obs, interval=c(25,95)))
```

## `neglog()`
`neglog(fcst, obs, at=NULL, after=NULL)` calculates the negative log score of a forecast.
`fcst` must contain raw data with 2 or more realizations per row.
It uses a Kernel Density Estimation (KDE) to obtain a probability distribution for each point in time.
If `f(x)` is the calculated probability distribution and `x0` is the corresponding observation, then the negative log score at that point in time is `-log(f(x0))`.

`at` and `after` can be used to specify which point in time to return the score of.
If both are left `NULL`, then all the calculated scores will be returned as part of a data frame.
`at` specifies a particular time, while `after` specifies a time relative to `fcst$forecast_time`.

### Examples

```{r neglog_examples}

# `rnorm(20) + 10`
d <- c(10.609344, 10.383797, 11.102006, 10.232616, 11.372632, 11.489963, 10.359282, 10.303749,  7.477219,  9.612921,  8.568241, 11.467244,  9.979756, 10.226105, 9.592584,  9.582751,  8.674618,  8.706757,  9.810594, 10.752879)

fc <- create_forecast(
  dplyr::tibble(time=1:5, raw=list(c(d, d, d, d, d))),
  forecast_time=2)

obs <- data.frame(time=1:5, raw=c(2, 7, 10, 11, 100))

print(neglog(fc, obs, at=3))
```