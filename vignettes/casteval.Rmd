---
title: "Automate forecast evaluation using `{casteval}`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Automate forecast evaluation using `{casteval}`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  strip.white=TRUE
)

library(casteval)
```


# Overview

`{casteval}` is an R package that helps you automate the evaluation of time series forecasts.
It provides functionality for formatting, processing, scoring, and visualizing forecasts.

A typical workflow using `{casteval}` might go as follows:

1. We pass forecast data to `create_forecast()`, which returns a forecast object in a standardized format
2. We pass the forecast object and corresponding observations into scoring functions such as `bias()`, `log_score()`, `accuracy()`, which evaluate the forecast
3. We pass the forecast object and corresponding observations into plotting functions such as `plot_forecast()`, which lets us visualize the forecast. Scoring functions can also work together with plotting functions in order to help visualize forecast scores

In this vignette, we demonstrate `{casteval}`'s main functionality via deliberately simple examples. For a more realistic start-to-finish demonstration of the package's usage with real forecasts, please see [`vignette("denmark2020")`](denmark2020.html).

# Data format

`{casteval}` expects the data you pass it to be in certain formats.
In particular:

- *Forecast data frames* contain forecast data
- *Forecast objects* contain metadata about a forecast, as well as a forecast data frame
- *Observations data frames* contain observations data

`{casteval}` contains tools which aid in the creation and manipulation of these objects.
These tools are described in later sections.

## Forecast data frames

All forecast data frames contain a `time` column, which can contain either numbers, dates, or date-times.
In addition, they should contain either unsummarized or summarized forecast data, but not both.

Unsummarized data is stored in a `val` column.
A `sim` column may optionally be provided to specify simulation numbers in an ensemble of data.

```{r fdf_unsummarized}
# unsummarized forecast over with numeric times, without simulation numbers
data.frame(
  time=c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),
  val=c(100,101,102,110,111,112,120,121,122,130,131,132,140,141,142)
)

# unsummarized forecast data with dates, with simulation numbers
data.frame(
  time=lubridate::as_date(c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5)),
  sim=c(1,2,3,1,2,3,1,2,3,1,2,3,1,2,3),
  val=c(100,101,102,110,111,112,120,121,122,130,131,132,140,141,142)
)
```

Summarized data may be stored in the following columns:

- Quantile columns must start with `val_q` followed by a number from 0 to 100, e.x. `val_50` would be the median
- The mean column must be named `val_mean`

Note that summarized data never contains a `sim` column.

```{r fdf_summarized}
# summarized forecast data with the 25th, 50th, and 75th percentiles
data.frame(
  time=lubridate::as_datetime(1:5),
  val_q25=c(100,105,103,104,105),
  val_q50=c(201, 210, 205, 201, 200),
  val_q75=c(304, 305, 303, 303, 302)
)

# summarized forecast data with the mean, and the 2.5th and 97.5th percentiles
data.frame(
  time=1:5,
  val_q2.5=c(100,103,104,105,102),
  val_mean=c(150,155,160,155,154),
  val_97.5=c(200,200,2204,205,206)
)
```

All data columns as well as the `sim` column must be numeric.

## Forecast objects

A forecast object is a list with the following fields:

- `data`: a forecast data frame (see above)
- `name`: (optional) the name of the forecast
- `forecast_time`: (optional) the time that the forecast was created. Its type must match that of the time column in `data`

Scoring functions will take `forecast_time` into account when scoring if it is provided.
Plotting functions will use `name` to title the plots they produce.

`{casteval}` provides a function for creating forecast objects, `create_forecast()`, which we describe below.
We recommend against creating or modifying forecast objects by hand, but it is useful to know what they look like.

```{r forecast_object}
# a forecast object with no optional metadata
list(
  data=data.frame(
    time=1:5,
    val=6:10
  ),
  name=NULL,
  forecast_time=NULL
)

# a forecast object with metadata
list(
  data=data.frame(
    time=lubridate::as_date(1:5),
    val=6:10
  ),
  name="A forecast",
  forecast_time=lubridate::as_date(3)
)
```

## Observations data frames

All observations data frames contain a `time` column and a `val_obs` column.
Similar to forecast data frames, `time` may be either numeric, dates, or date-times.
`val_obs` must be numeric.

An observations data frame may also contain a `score` column, which usually gets attached by a scoring function, and can be passed to some plotting functions.
`score` can have many different types, but it is typically numeric or logical.

```{r obsdf}
# An observations data frame
data.frame(
  time=1:5,
  val_obs=c(50,60,55,57,59)
)

# An observations data frame that holds scoring information for some forecast
data.frame(
  time=lubridate::as_date(1:5),
  val_obs=c(50,60,55,57,59),
  score=c(1.5, 0, -1, 5, 6)
)
```

# Creating forecast objects

You can create forecast objects using `create_forecast()`.
Its first argument is `dat`, which may be one of the following formats:

- A forecast data frame, as described above
- A list with fields `time` and `vals`, where:
  - `time` is a vector of either numbers, dates, or date-times
  - `vals` is a list of numeric vectors, where each vector is the same length as `time`. Each vector corresponds to a realization in the forecast

In addition, `create_forecast()` accepts the optional arguments `name` and `forecast_time`, which will be stored in the forecast object as metadata.

`create_forecast()` performs input validation on the provided parameters.
For example, it checks that:

- `forecast_time`'s type is consistent with `dat`
- quantile values are logically possible (e.x. the median can't be less than the 25th percentile)
- there are no conflicting rows (e.x. there can't be two rows with the same time providing the mean)

```{r create_forecast}
# forecast data with 4 time points and an ensemble of 3 simulations
dat1 <- list(
  time=1:4,
  vals=list(
    c(100, 102, 110, 108),
    c(200, 195, 197, 196),
    c(300, 301, 300, 302)
  )
)

fc1 <- create_forecast(dat1, name="forecast 1", forecast_time=3)

# the same data but formatted as a forecast data frame
dat2 <- data.frame(
  time=rep(1:4, each=3),
  sim=rep(1:3, times=4),
  val=c(100, 200, 300, 102, 195, 301, 110, 197, 300, 108, 196, 302)
)

fc2 <- create_forecast(dat2, name="forecast 2", forecast_time=3)

print(fc1)

# aside from the order of rows, the resulting forecast data frames are identical
waldo::compare(dplyr::arrange(fc1$data, time), fc2$data)

# mean-and-quantiles forecast data
dat3 <- data.frame(
  time=1:5,
  val_q2.5=c(100,103,104,105,102),
  val_mean=c(150,155,160,155,154),
  val_q97.5=c(200,200,2204,205,206)
)

# note how we omit `forecast_time`
fc3 <- create_forecast(
  dat3,
  name="forecast 3"
)

print(fc3)
```

# Scoring

Scoring functions accept the following arguments:

- A forecast object `fcst`
- An observations data frame `obs`
- Additional arguments specific to particular scoring functions

In order for scoring to be possible, `fcst` and `obs` must use the same time type.
That is to say, `fcst$data$time` and `obs$time` must have the same type.

If `fcst$forecast_time` is not `NULL`, then all data prior to `fcst$forecast_time` will be ignored when scoring `fcst`.

If `fcst` or `obs` contain times not contained by the other, they will be ignored when scoring.

### The `summarize` flag
Many scoring functions calculate intermediate values for each time point, and then select/combine those scores in order to return a single value.
These functions accept an optional `summarize` parameter, which is a boolean.

If `summarize` is set to `TRUE` (the default), the scoring function will usually return the score as a single number (one exception being `accuracy()`, which might return a vector of numbers).

Otherwise, it will return a data frame with `time`, `obs`, and `score` columns, containing the observations and scores calculated for each time point that was scored.
The type of the `score` column is not necessarily numeric (for example, in `accuracy()`, it is logical instead).
One use of these unsummarized values is for color-coding observation points when graphing them.

The currently supported scoring functions are described below.

## Accuracy

`accuracy(fcst, obs, quant_pairs=NULL, summarize=TRUE)` calculates the rate at which the observations fall inside a quantile interval of the forecast data.

`quant_pairs` should be one of:

- `NULL`
- a pair of quantiles (e.x. `c(2.5, 97.5)`)
- a list of pairs of quantiles (e.x. `list(c(2.5, 97.5), c(10, 90))`)

If `quant_pairs` is not `NULL`, a separate score will be calculated for each given pair of quantiles.
If `quant_pairs` is `NULL`, then `fcst` should contain quantile data, and the quantile pairs for scoring will be inferred from `fcst`'s quantile columns.

If `summarize` is `TRUE`, then the score(s) will be returned as a vector of numbers from 0 to 1, one score per quantile pair.

If `summarize` is `FALSE`, then the returned data frame will contain an additional column named `pair`, which will indicate which quantile pair each row corresponds to.

### Examples

```{r accuracy_examples}
# A forecast with unsummarized data
fc1 <- create_forecast(data.frame(
  time=rep(1:5, each=11),
  val=rep(0:10, 5)
))

# A forecast with quantile data
fc2 <- create_forecast(dplyr::tibble(
  time=1:5,
  val_q5=c(0.5,0.5,0.5,0.5,0.5),
  val_q10=c(1,1,1,1,1),
  val_q25=c(2.5,2.5,2.5,2.5,2.5),
  val_q75=c(7.5,7.5,7.5,7.5,7.5),
  val_q90=c(9,9,9,9,9),
  val_q95=c(9.5,9.5,9.5,9.5,9.5)
))

# Another forecast with quantile data
fc3 <- create_forecast(data.frame(
    time=1:5,
    val_q2.5=c(6,6,6,6,6),
    val_q97.5=c(10,10,10,10,10)
))

obs <- data.frame(time=1:5, val_obs=c(0, 2.4, 5, 9.5, 10))

# Calculate accuracy from unsummarized data
accuracy(fc1, obs, quant_pairs=c(25, 75))

# Calculate the accuracy for every quantile pair present
accuracy(fc2, obs)

# Calculate the accuracy for a subset of quantile pairs
accuracy(fc2, obs, quant_pairs=list(c(5,95), c(25,75)))

# Calculate accuracy for only one quantile pair
accuracy(fc2, obs, quant_pairs=c(5, 95))

# If `forecast_time` is NULL, every time point in the forecast will be scored
accuracy(fc3, obs)

# Otherwise, everything prior to `forecast_time` will be ignored
fc3$forecast_time <- 3
accuracy(fc3, obs)

# We can see what is happening behind the scenes by passing `summarize=FALSE`
df <- accuracy(fc3, obs, summarize=FALSE)
df
mean(df$score)

# `pair` column maps rows to quantile pairs
accuracy(fc2, obs, summarize=FALSE)
```

## Logarithmic score
`log_score(fcst, obs, at=NULL, after=NULL, summarize=TRUE, bw=NULL)` calculates the (positive) log score of a forecast.
It uses Kernel Density Estimation (KDE) to obtain a probability distribution for each point in time in the forecast.
If `f(x)` is the estimated probability distribution and `x_0` is the corresponding observation, then the log score at that point in time is `log(f(x_0))` (`log()` is the natural logarithm).

`fcst` must contain unsummarized data with 2 or more values per time point.

If `summarize` is TRUE, then exactly one af `at` (a compatible time) and `after` (a number) must be provided.
The score at time equal to `at` or `fcst$forecast_time + after` will be returned.

If `summarize` is FALSE, then `at` and `after` are ignored, and the output will be a data frame as described above.

The KDE requires a bandwidth in order to calculate the distribution.
If `bw` is left `NULL`, then a reasonable bandwidth will be automatically determined.
Otherwise, the value of `bw` (which must be a number greater than 0) will be used as the bandwidth.

### Visualizing the KDE
When evaluating forecasts using `log_score()` you may want to inspect inspect the KDE as a sanity check, especially if your data is very sparse.
You may also want to see how setting the `bw` parameter affects the resulting distribution, or whether the automatically calculated binwidth is sufficient.

`plot_KDE()` allows you to do this.
Like `log_score()`, it accepts the parameters `fcst`, `obs` (which is now optional), `at`, `after`, and `bw`.
It also accepts the optional parameters `from`, `to`, `n`, and `binwidth` (not to be confused with bandwidth). See `?plot_KDE` for a detailed explanation of these extra parameters.

`plot_KDE()` will plot the following elements:

- the data points of the `fcst` and/or `obs` at the time point specified by `at` or `after`
- a histogram showing the distribution of `fcst`'s data points (once again specified by `at` or `after`), normalized to integrate to 1
- the density curve calculated by the KDE

### Examples

```{r log_score_examples}
# generated using `rnorm(20) + 10`
d <- c(10.609344, 10.383797, 11.102006, 10.232616, 11.372632, 11.489963, 10.359282, 10.303749,
  7.477219,  9.612921,  8.568241, 11.467244,  9.979756, 10.226105, 9.592584,  9.582751,  8.674618,
  8.706757,  9.810594, 10.752879)

fcst <- create_forecast(
  data.frame(time=rep(1:5, each=20), val=rep(d,5)),
  forecast_time=2
)

obs <- data.frame(time=1:5, val_obs=c(2, 7, 10, 11, 100))

# get the score at time 3
log_score(fcst, obs, at=3)

# get the score at time `fcst$forecast_time + 2` (4)
log_score(fcst, obs, after=2)

# get all the scores as part of a data frame
log_score(fcst, obs, summarize=FALSE)

# check the KDE at time 4 with default binwidth
# the observation point shows up as a vertical line
plot_KDE(fcst, obs, at=4)

# check the KDE at time 4 with a too-low binwidth (making the resulting distribution very jagged)
plot_KDE(fcst, obs, at=4, bw=0.2)

# check the KDE at time 4 with a too-high binwidth (resulting in an underconfident distribution)
plot_KDE(fcst, obs, at=4, bw=2)
```

## Bias
`bias(fcst, obs, summarize=TRUE)` calculates how much a forecast overpredicts and underpredicts each observed value, and returns the result as a number between -1 and 1, where -1 means 100% underprediction and 1 means 100% overprediction.

It searches for these three kinds of data:

1. unsummarized data (`val`)
2. mean data (`val_mean`)
3. median data (`val_q50`)

It uses the first kind that it can find to calculate the bias.

## Defining your own scoring functions
You are free to define your own scoring functions and use them just like `{casteval}`'s scoring functions.
Like the functions described above, it should accept a forecast object `fcst`, an observations data frame `obs`, and possibly additional arguments.
If it implements the `summarize` flag (see above), then it can be used in plotting functions as well.


# Visualization

`{casteval}` provides plotting functions which allow you to visualize your forecasts, observations, and sometimes scores.
Several modular functions (`plot_ensemble()`, `plot_observations()`, `plot_quantile_intervals()`) implement individual plotting functionality, while the more user-friendly `plot_forecast()` combines them all.
We describe these functions below.

## Plot a forecast

`plot_forecast(fcst, obs=NULL, quant_pairs=NULL, score=NULL)` plots a forecast. It also optionally overlays observations, quantile intervals, and color-codes the observations based on score.

`quant_pairs` is like the parameter with the same name in `accuracy()`.
The only difference is that an error will not be raised if `quant_pairs` is `NULL` and quantile pairs can't be inferred, or if `quant_pairs` is an empty list (in which case quantile intervals simply won't be plotted).

`score` should be a scoring function which supports the `summarize` flag.
`plot_forecast()` will run `score(fcst, obs, summarize=FALSE)`, and use the resulting data frame's `score` column to color code the observation points.

Some wrapping of the builtin scoring functions may be required before passing them to `plot_forecast()`.
For example, `accuracy()` will require a single quantile pair to be passed to it as well.

```{r plot_forecast_examples}
# Create a forecast
fc <- create_forecast(list(
  time=1:10,
  vals=list(
    c(1,2,3,5,4,5,4,6,6,5),
    c(1,3,5,4,6,5,7,9,8,8),
    c(1,4,3,4,5,6,5,3,2,2),
    c(1,2,4,5,7,8,7,9,10,9)
  )
))

# Plot it
plot_forecast(fc)

# Plot it and display 3 quantile intervals
plot_forecast(fc, quant_pairs=list(c(25,75), c(2.5,97.5), c(5,95)))

# Create some observations
obs <- data.frame(time=1:10, val_obs=c(1,4,8,10,11,8,5,3,3,2))

# Plot them over the forecast and its confidence intervals
plot_forecast(fc, obs=obs, quant_pairs=list(c(25,75), c(2.5,97.5), c(5,95)))

# We use a function factory to wrap accuracy() (see `?make_accuracy`)
acc <- make_accuracy(c(5,95))
# Identify the observations inside the 5%-95% quantile interval
plot_forecast(fc, obs=obs, quant_pairs=list(c(25,75), c(2.5,97.5), c(5,95)), score=acc)

# Do the same thing with `log_score()`
# `graph_forecast()` automatically passes `summarize=FALSE` to
# scoring functions in order to obtain the score for each day
plot_forecast(fc, obs=obs, score=log_score)
```
