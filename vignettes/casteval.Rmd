---
title: "Automate forecast evaluation using `{casteval}`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Automate forecast evaluation using `{casteval}`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  strip.white=TRUE
)

library(casteval)
```


# Overview
`{casteval}` is an R package that helps you automate the evaluation of time series forecasts.
It provides functionality for formatting, processing, scoring, and visualizing forecasts.

*Note: Many examples in this vignette are deliberately contrived/simplified in order to better illustrate functionality. For a more realistic start-to-finish demonstration of the package's usage, see [this vignette](denmark2020.html).*

# Input formatting
*Note: As this is a work in progress, the number of formats supported is still limited*

`{casteval}` accepts the following forecast formats as input:

- A single data frame with a `time` column and one or more data columns (see below)
- A list of data frames, each with a `time` column and a `raw` data column
- A named list `l`, where `l$time` is a vector of times and `l$ensemble` is a list of vectors, each one the same length as `l$time`

Times can be one of the following types:

- `numeric` (-1, 0, 1, 1.5, etc.)
- `Date` (_e.g._ from `{lubridate}`)
- date-time formats `POSIXct` and `POSIXt`

All data columns must contain numeric data.
The current supported data columns are:

- `raw`: values for individual realisations of a forecast
- `mean`: mean value for each time point of an ensemble
- `quant_x`: quantile for each time point of an ensemble, where `x` is a percentage from 0 to 100 (_e.g._, `quant_50`, `quant_2.5`, `quant_97.5`, etc.)

## Examples

The following are examples of valid forecast inputs to `{casteval}`:

```{r input_formats}
# Create some dates and date-times for convenience
dates <- c(lubridate::ymd("2024-01-01"), lubridate::ymd("2024-01-02"), lubridate::ymd("2024-01-03"))
datetimes <- c(lubridate::ymd_hms("2024-02-01_12:00:00"),
  lubridate::ymd_hms("2024-02-01_13:00:00"),
  lubridate::ymd_hms("2024-02-01_14:00:00"))

## Single data frame format

# A forecast with dates and raw data points
A <- data.frame(
  time=dates,
  raw=c(400, 450, 500)
)
A

# A forecast with date-times and quartiles
B <- data.frame(
  time=datetimes,
  quant_25=c(50, 60, 70),
  quant_50=c(100, 110, 120),
  quant_75=c(150, 160, 170)
)
B

# A forecast with numeric times, the mean, and 95% confidence interval
C <- data.frame(
  time=c(1, 2, 3),
  mean=c(1000, 900, 800),
  quant_2.5=c(950, 850, 750),
  quant_97.5=c(1050, 950, 850)
)
C

# A forecast with raw data containing 3 realizations over 4 days
# We use tibbles here to make entering the list-column easier
time_vec <- 1:4
realized_t1 <- c(100, 200, 300)
realized_t2 <- c(102, 195, 301)
realized_t3 <- c(110, 197, 300)
realized_t4 <- c(108, 196, 302)
D <- dplyr::tibble(
  time=time_vec,
  raw=list(realized_t1, realized_t2, realized_t3, realized_t4)
)
D

## List of data frames format

# A forecast with the same data as D, but with one data frame for each realization
df1 = dplyr::tibble(time=1:4, raw=c(100, 102, 110, 108))
df2 = dplyr::tibble(time=1:4, raw=c(200, 195, 197, 196))
df3 = dplyr::tibble(time=1:4, raw=c(300, 301, 300, 302))
E <- list(df1, df2, df3)
E

## Ensemble of realizations format

# A forecast with the same data as D, but with one vector for each realization
F <- list(
  time=1:4,
  ensemble=list(
    c(100, 102, 110, 108),
    c(200, 195, 197, 196),
    c(300, 301, 300, 302)
  )
)
F
```

*Note: The format of the `raw` column may change in future versions of the package*

As demonstrated above, the `raw` column can store multiple realizations as a list of vectors, where each vector corresponds to a time point in the forecast.
For instance, the `j`th value of the vector stored in row `i` of the input data frame would give the value of the `j`th realisation for time `i`. In this format, `{casteval}` expects that all vectors in such a list-column are the same length (missing values can be specified using `NA`).

# Passing forecasts to `{casteval}`

We start by passing our forecast to `create_forecast()`, which accepts a forecast in any of the above formats, as well as several optional arguments.
This function:

- Performs input validation
- Infers the format of the given data
- Converts the data into a standardized format
- Returns the forecast and its metadata as a named list

The named list contains fields such as `$name` (the name of the forecast), `$forecast_time` (when the forecast was generated), and `$data`, which is a data frame containing the formatted forecast data.
This named list can then be passed to any function in `{casteval}` which accepts a forecast.

## Examples

```{r create_forecast}
# A forecast with a name
fc1 <- create_forecast(A, name="Jan 1 to Jan 3 2024 forecast")

# `name` and `forecast_time` are optional, and default to NULL
fc2 <- create_forecast(B)

# A forecast with a name and a forecast time
# All data from before the forecast time will be ignored when scoring the forecast
# The given forecast time must have the same type as the values in the `time` column
fc3 <- create_forecast(C, name="Mean-and-quantiles forecast", forecast_time=2)

# Metadata and data are easily accessible
fc3$name
fc3$forecast_time
fc3$time_type
fc3$data_types
fc3$data

# A forecast of 3 realizations over 4 days
fc4 <- create_forecast(D)
fc4$data

# Same as fc4
fc5 <- create_forecast(E)
waldo::compare(fc4, fc5)

# Same as fc4 
fc6 <- create_forecast(F)
waldo::compare(fc4, fc6)
```

As demonstrated above, raw data can be entered in multiple different formats, depending on which is most convenient for you.

# Observations

Observations are data frames with a `time` column and a numeric `obs` column.
Note how observations are simply data frames, whereas forecasts are encapsulated in a named list.
The reasoning for this is that forecasts contain certain metadata (such as `forecast_time`) which affect the way they are evaluated.

*Note: This may change in future versions if it turns out that observations require metadata too, or if there is a better way to store metadata.*

```{r observations}
# An observations data frame with numeric times
obs <- data.frame(time=1:3, obs=c(10,15,12))
```

# Scoring

Scoring functions accept the following arguments:

- A forecast object `fcst` (such as the ones outputted by `create_forecast()`)
- A data frame of observations `obs` (as described above)
- Additional arguments specific to particular scoring functions

### Forecast-observations compatibility
`fcst` and `obs` must use the same time type for scoring to be possible.
That is to say, `fcst$data$time` and `obs$time` must contain elements of the same type.

If `fcst$forecast_time` is not `NULL`, then all data prior to `fcst$forecast_time` will be ignored when scoring `fcst`.

If `obs` contains data for time points that `fcst` does not have, those time points will be ignored.
However, the reverse cannot happen (if `fcst` contains time points that `obs` does not have, an error will be raised).

*Note: In the future a flag might be added to tell the scoring functions to discard rows with missing observations.*

### `summarize` flag
Many scoring functions calculate intermediate values for each time point, and then select/summarize those scores as a single value.
These functions accept a `summarize` parameter.

If `summarize` is set to `TRUE` (the default), the scoring function will return the score as a single number.

Otherwise, it will return a data frame with `time`, `obs`, and `score` columns, containing the observations and scores calculated for each time point.
The type of the `score` column is not necessarily numeric (for example, in `accuracy()`, it contains booleans).
One use of these unsummarized values is for color-coding observation points when graphing them.

The currently supported scoring functions are described below.

## Accuracy

TODO revise this section after fixing `accuracy()`

`accuracy(fcst, obs, interval=NULL, summarize=TRUE)` calculates the rate at which the observations fall inside a confidence interval predicted by the forecast.
It returns a number from 0 to 1.

If `fcst` contains raw data, `interval` must be a vector of two percentages from 0 to 100.
The corresponding quantiles will be calculated from the raw data and used to calculate the score.

If `fcst` contains quantile data and `interval` is left as `NULL`, then `accuracy()` will try to use the lowest and highest provided quantiles to calculate the score.
If `interval` is provided, then `accuracy()` will use the corresponding quantiles in `fcst` to calculate the score.

### Examples

```{r accuracy_examples}
# A forecast with raw data
fc1 <- create_forecast(dplyr::tibble(
  time=1:5,
  raw=list(0:10, 0:10, 0:10, 0:10, 0:10)
))

# A forecast with quantile data
fc2 <- create_forecast(dplyr::tibble(
  time=1:5,
  quant_5=c(1,1,1,1,1),
  quant_25=c(2.5,2.5,2.5,2.5,2.5),
  quant_75=c(7.5,7.5,7.5,7.5,7.5),
  quant_95=c(9.5,9.5,9.5,9.5,9.5)
))

# A forecast with less symmetrical quantile data
fc3 <- create_forecast(dplyr::tibble(
  time=1:5,
  quant_25=c(2.5,2.5,2.5,2.5,2.5),
  quant_50=c(5,5,5,5,5),
  quant_95=c(9.5,9.5,9.5,9.5,9.5)
))

# Another forecast with quantile data
fc4 <- create_forecast(dplyr::tibble(
    time=1:5,
    quant_25=c(6,6,6,6,6),
    quant_75=c(10,10,10,10,10)
))

obs <- data.frame(time=1:5, obs=c(0, 2.4, 5, 9.5, 10))

# Calculate accuracy using the 50% confidence interval
accuracy(fc1, obs, interval=c(25, 75))

# Calculate accuracy using highest and lowest quantiles (5% and 95% in this case)
accuracy(fc2, obs)

# Calculate accuracy using provided quantiles.
accuracy(fc2, obs, interval=c(25, 95))

# `accuracy()` refuses to automatically use the highest and lowest quantiles if
# they are not symmetrical
try(accuracy(fc3, obs))

# Specifying an interval fixes this
accuracy(fc3, obs, interval=c(25,95))

# If `forecast_time` is NULL, every time point in the forecast will be scored
accuracy(fc4, obs)

# Otherwise, everything prior to `forecast_time` will be ignored
fc4$forecast_time <- 3
accuracy(fc4, obs)

# We can see what is happening behind the scenes by passing `summarize=FALSE`
df <- accuracy(fc4, obs, summarize=FALSE)
df
mean(df$score)
```

## Negative log score
`neglog(fcst, obs, at=NULL, after=NULL)` calculates the negative log score of a forecast.
`fcst` must contain raw data with 2 or more realizations per row.
It uses Kernel Density Estimation (KDE) to obtain a probability distribution for each point in time in the forecast.
If `f(x)` is the calculated probability distribution and `x0` is the corresponding observation, then the negative log score at that point in time is `-log(f(x0))`, where `log` is the natural logarithm.

`at` and `after` can be used to specify which point in time to return the score of.
If both are left `NULL`, then all the calculated scores will be returned as part of a data frame.
`at` specifies a particular time, while `after` specifies a time relative to `fcst$forecast_time`.

### Examples

```{r neglog_examples}

# `rnorm(20) + 10`
d <- c(10.609344, 10.383797, 11.102006, 10.232616, 11.372632, 11.489963, 10.359282, 10.303749,
  7.477219,  9.612921,  8.568241, 11.467244,  9.979756, 10.226105, 9.592584,  9.582751,  8.674618,
  8.706757,  9.810594, 10.752879)

fcst <- create_forecast(
  dplyr::tibble(time=1:5, raw=list(c(d, d, d, d, d))),
  forecast_time=2
)

obs <- data.frame(time=1:5, obs=c(2, 7, 10, 11, 100))

# get the score at time=3
neglog(fcst, obs, at=3)

# get the score at `fcst$forecast_time + 2` (4)
neglog(fcst, obs, after=2)

# get all the scores as part of a data frame
neglog(fcst, obs, summarize=FALSE)

# `at` and `after` are mutually exclusive
try(neglog(fcst, obs, at=3, after=1))
```

## Defining your own scoring functions
TODO

# Visualization

*Note: `{casteval}` implements several more modular graphing functions which are not currently exported, such as `graph_observations()`, `graph_quantiles()`, etc. If it would be useful to have these available then this may change*

`graph_forecast(fcst, obs=NULL, confs=NULL, score=NULL)` graphs a forecast. It also optionally overlays observations, confidence intervals, and color-codes the observations based on score.

```{r graph_forecast_examples}
# Create a forecast
fc1 <- create_forecast(list(
  time=1:10,
  ensemble=list(
    c(1,2,3,5,4,5,4,6,6,5),
    c(1,3,5,4,6,5,7,9,8,8),
    c(1,4,3,4,5,6,5,3,2,2),
    c(1,2,4,5,7,8,7,9,10,9)
  )
))

# Graph it
graph_forecast(fc1)

# Graph it and display the 50%, 90%, and 95% confidence intervals
graph_forecast(fc1, confs=c(50,95,90))

# Create some observations
obs <- data.frame(time=1:10, obs=c(1,4,8,10,11,8,5,3,3,2))

# Graph them over the forecast and its confidence intervals
graph_forecast(fc1, obs=obs, confs=c(50,90,95))

# Wrap `accuracy()` to get the 90% confidence interval
acc90 <- \(...) accuracy(..., interval=c(5,95))
# Use `acc90()` to identify the observations outside the condfidence interval
graph_forecast(fc1, obs=obs, confs=c(50,90,95), score=acc90)

# Do the same thing with `neglog()`
# `graph_forecast()` automatically passes `summarize=FALSE` to scoring functions in order to obtain the score for each day
graph_forecast(fc1, obs=obs, score=neglog)
```